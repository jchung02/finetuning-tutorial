# Use case: DeepSpeed ZeRO Stage 2 â€” shards optimizer states and gradients across GPUs
#           but keeps a full copy of model parameters on each GPU.
#           Good balance between memory savings and communication overhead.
# Run: accelerate launch --config_file configs/deepspeed_zero2.yaml multi-gpu/parallelism_accelerate.py

compute_environment: LOCAL_MACHINE
distributed_type: DEEPSPEED
mixed_precision: bf16
num_processes: 2
num_machines: 1
machine_rank: 0
main_training_function: main
downcast_bf16: 'no'
enable_cpu_affinity: false
gpu_ids: all
same_network: true
use_cpu: false

deepspeed_config:
  zero_stage: 2
  gradient_accumulation_steps: 8
  gradient_clipping: 1.0
  offload_optimizer_device: none               # OPTIONAL: set to 'cpu' to offload optimizer states
  offload_param_device: none
  zero3_init_flag: false
  zero3_save_16bit_model: false
